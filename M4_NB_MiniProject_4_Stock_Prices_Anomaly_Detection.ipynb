{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M4_NB_MiniProject_4_Stock_Prices_Anomaly_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilav/neuralnetwork/blob/main/M4_NB_MiniProject_4_Stock_Prices_Anomaly_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFBl3DsqB3AE"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "\n",
        "##  A program by IISc and TalentSprint\n",
        "\n",
        "### Mini Project Notebook: Stock Prices Anomaly Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maritime-miami"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95F1ym6qB8VU"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* apply PCA based analysis on various stocks data\n",
        "* analyze and create time series data\n",
        "* implement LSTM auto-encoders\n",
        "* detect the anomalies based on the loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8aczZmzvXTc"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N04YT8wkBV8"
      },
      "source": [
        "Autoencoder Neural Networks try to learn data representation of its input. Usually, we want to learn an efficient encoding that uses fewer parameters/memory. The encoding should allow for output similar to the original input. In a sense, weâ€™re forcing the model to learn the most important features of the data using as few parameters as possible.\n",
        "\n",
        "LSTM autoencoder is an encoder that makes use of LSTM encoder-decoder architecture to compress data using an encoder and decode it to retain original structure using a decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A3CeBTlkclZ"
      },
      "source": [
        "**Anomaly Detection**\n",
        "\n",
        "Anomaly detection refers to the task of finding/identifying rare events/data points. Some applications include - bank fraud detection, tumor detection in medical imaging, and errors in written text.\n",
        "\n",
        "A lot of supervised and unsupervised approaches for anomaly detection have been proposed. Some of the approaches include - One-class SVMs, Bayesian Networks, Cluster analysis, and Neural Networks.\n",
        "\n",
        "We will use an LSTM Autoencoder Neural Network to detect/predict anomalies (sudden price changes) in the S&P 500 index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgx1PkHfCDyJ"
      },
      "source": [
        "## Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JlX9ivNquus"
      },
      "source": [
        "This mini-project consists of two parts and two different stock price datasets:\n",
        "\n",
        "### PART A\n",
        "\n",
        "Using the **S&P 500 stock prices data of different companies**, we will perform a PCA based analysis. \n",
        "\n",
        "### PART B\n",
        "\n",
        "Using the **S&P 500 stock price index time series data**, we will perform anomaly detection in the stock prices across the years. The dataset chosen is is S&P500 Daily Index a .csv format with one column with a daily timestamp and the second column with the raw, un-adjusted closing prices for each day. This long term, granular time series dataset allows researchers to have a good sized publicly available financial dataset to explore time series trends or use as part of a quantitative finance project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HDD5ANilAFk"
      },
      "source": [
        "Detect the stock price anomalies by implementing an LSTM autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "operating-latter"
      },
      "source": [
        "## Grading = 20 Points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82-MCqP0yFM2",
        "cellView": "form"
      },
      "source": [
        "#@title Download dataset\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/SPY.csv\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/prices.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOD5BSv-zts3"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.layers import LSTM, RepeatVector, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential, Model\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saS-392nl9p0"
      },
      "source": [
        "## PCA Analysis (PART-A)\n",
        "\n",
        "Principal Component Analysis (PCA) decomposes the data into many vectors called principal components. These summaries are linear combinations of the input features that try to explain as much variance in the data as possible. By convention, these principal components are ordered by the amount of variance they can explain, with the first principal component explaining most of the data.\n",
        "\n",
        "Perform PCA based analytics on the stock prices data from different companies.\n",
        "\n",
        "Hint: Refer to the article [here](https://towardsdatascience.com/stock-market-analytics-with-pca-d1c2318e3f0e)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAQhjOKMPXSO"
      },
      "source": [
        "### Load and pre-process the prices data (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Red8vqbEmjRk"
      },
      "source": [
        "prices_path = \"prices.csv\"\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGfxFqC2Pfv6"
      },
      "source": [
        "### Apply PCA (6 points)\n",
        "\n",
        "* plot the explained variance ratio. Hint: `pca.explained_variance_ratio_`\n",
        "* Represent the components which preserve maximum information and plot to visualize\n",
        "* Compute the daily returns of the 500 company stocks. Hint: See the following [reference](https://towardsdatascience.com/stock-market-analytics-with-pca-d1c2318e3f0e).\n",
        "* Plot the stocks with most negative and least negative PCA weights in the pandemic period (Year 2020). Use reference as above. Discuss the least and most impacted industrial sectors in terms of stocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr-26wOaQz79"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR9EtC0WPyiW"
      },
      "source": [
        "#### Apply T-SNE and visualize with a graph (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWfaROS1P4Xj"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AjTe8ZRO_QD"
      },
      "source": [
        "## Anomaly Detection (PART-B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKyZNQkWUnI8"
      },
      "source": [
        "### Load and Preprocess the data\n",
        "\n",
        "* Inspect the S&P 500 Index Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-3R13wKK1rz"
      },
      "source": [
        "path = 'SPY.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2pjjH-GEX9C"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bguM7haxU3PL"
      },
      "source": [
        "#### Data Preprocessing (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzwW8HgeIoa2"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epg_QXw5YWXW"
      },
      "source": [
        "### Create time series data ( 1 point)\n",
        "\n",
        "Select the variable (column) from the data and create the series of data with a window size.\n",
        "\n",
        "Refer [LSTM Autoencoder](https://medium.com/swlh/time-series-anomaly-detection-with-lstm-autoencoders-7bac1305e713)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp89-jBZpskM"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nZrpfm9cJeX"
      },
      "source": [
        "### Build an LSTM Autoencoder ( 2 points)\n",
        "\n",
        "Autoencoder should take a sequence as input and outputs a sequence of the same shape.\n",
        "\n",
        "Hint: [LSTM Autoencoder](https://medium.com/swlh/time-series-anomaly-detection-with-lstm-autoencoders-7bac1305e713)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir1jbzvDI3ij"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL8k_JAjfhLt"
      },
      "source": [
        "### Train the Autoencoder (1 point)\n",
        "\n",
        "* Compile and fit the model with required parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBqAR3SAapfJ"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW93bYQXcf2I"
      },
      "source": [
        "#### Plot metrics and evaluate the model (2 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GYE03C1TUv0"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C8bQAqZcqiw"
      },
      "source": [
        "### Detect Anomalies in the S&P 500 Index Data (3 points)\n",
        "\n",
        "* Predict the data and calculate the loss\n",
        "* Define threshold and detect the anomalies\n",
        "\n",
        "Discuss the Impact of COVID19 pandemic on stock prices in terms of anomalies detected during the pandemic period in stock prices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm5uJwmuJiqt"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smjqrV0AP-D4"
      },
      "source": [
        "### Report Analysis\n",
        "\n",
        "* Discuss on the results of T-SNE and PCA\n",
        "* Dicuss about the results of LSTM autoencoder"
      ]
    }
  ]
}