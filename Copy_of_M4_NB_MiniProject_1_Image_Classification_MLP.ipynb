{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Copy of M4-NB_MiniProject_1_Image_Classification_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilav/neuralnetwork/blob/main/Copy_of_M4_NB_MiniProject_1_Image_Classification_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "another-optimum"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "\n",
        "##  A program by IISc and TalentSprint\n",
        "\n",
        "### Mini Project Notebook: Image Classification using Multi Layer Perceptron"
      ],
      "id": "another-optimum"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maritime-miami"
      },
      "source": [
        "## Learning Objectives"
      ],
      "id": "maritime-miami"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nljJR6CwfZN_"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* load and extract features of images\n",
        "\n",
        "* implement the Multi-Layer perceptron to classify images\n",
        "\n",
        "* implement simple neural network from keras"
      ],
      "id": "nljJR6CwfZN_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29152de7"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Traffic sign recognition is a challenging, real-world problem relevant for AI based transportation systems. Traffic signs show a wide range of variations between classes in terms of color, shape, and the presence of pictograms or text. However, there exist subsets of\n",
        "classes (e.g., speed limit signs) that are very similar to each other. Further, the classifier\n",
        "has to be robust against large variations in visual appearances due to changes in illumination, partial\n",
        "occlusions, rotations, weather conditions etc. Using a comprehensive traffic sign detection dataset, here we will perform classification of traffic signs, train and evaluate the different models and compare to the performance of MLPs."
      ],
      "id": "29152de7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58facc94"
      },
      "source": [
        "![img](https://paperswithcode.com/media/datasets/GTSRB-0000000633-9ce3c5f6_Dki5Rsf.jpg)"
      ],
      "id": "58facc94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "surprising-uruguay"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The data for this mini-project is from the German Traffic Sign Detection Benchmark [GTSDB](https://benchmark.ini.rub.de/gtsdb_dataset.html). This archive contains the training set used during the IJCNN 2013 competition. \n",
        "\n",
        "The German Traffic Sign Detection Benchmark is a single-image detection assessment for researchers with interest in the field of computer vision, pattern recognition and image-based driver assistance. It is introduced on the IEEE International Joint Conference on Neural Networks 2013. \n",
        "\n",
        "It features ...\n",
        "\n",
        "* The main archive FullIJCNN2013.zip includes the images (1360 x 800 pixels) in PPM format, the image sections containing only the traffic signs\n",
        "* A file in CSV format with the ground truth\n",
        "* A ReadMe.txt with more details."
      ],
      "id": "surprising-uruguay"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ],
      "id": "ih-oasWmdZul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfWGmjNHdZul"
      },
      "source": [
        "To build and improve upon a machine learning model for the classification of images and achieve a high accuracy final model."
      ],
      "id": "qfWGmjNHdZul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "operating-latter"
      },
      "source": [
        "## Grading = 10 Points"
      ],
      "id": "operating-latter"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "812a816f"
      },
      "source": [
        "#@title Download the data\n",
        "#!wget -qq https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "#!unzip -qq FullIJCNN2013.zip"
      ],
      "id": "812a816f",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import Required packages"
      ],
      "id": "abstract-stocks"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advisory-knowing"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.io import imread, imshow\n",
        "from sklearn import preprocessing\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Keras\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img"
      ],
      "id": "advisory-knowing",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp4bF_GJdZuo"
      },
      "source": [
        "### Data Loading and Feature Extraction (2 points)\n",
        "\n",
        "#### Get the features and labels of data\n",
        "\n",
        "* Extract the features of the images\n",
        "* Extract labels of the images\n",
        "* Resize the images to (30, 30) and convert to numpy 1-D array\n",
        "\n",
        "   Hint: [Link](https://machinelearningmastery.com/how-to-load-and-manipulate-images-for-deep-learning-in-python-with-pil-pillow/)"
      ],
      "id": "gp4bF_GJdZuo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXlevZ0LZYi8",
        "outputId": "b2fda614-cd7b-4771-8829-83b1170a4ae5"
      },
      "source": [
        "!pip install Pillow"
      ],
      "id": "aXlevZ0LZYi8",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-7OlO5qZQ7S",
        "outputId": "4475ebcc-0181-4fc8-ce3e-b4567b8861dc"
      },
      "source": [
        "# check Pillow version number\n",
        "import PIL\n",
        "print('Pillow Version:', PIL.__version__)"
      ],
      "id": "x-7OlO5qZQ7S",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pillow Version: 7.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNzXU_nfZvNU"
      },
      "source": [
        "data_dir = '/content/FullIJCNN2013'\n",
        "train_path = '/content/FullIJCNN2013/Train'\n",
        "test_path = '/content/FullIJCNN2013'\n",
        "IMG_HEIGHT = 30\n",
        "IMG_WIDTH = 30"
      ],
      "id": "bNzXU_nfZvNU",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHRpyQMjcx0g",
        "outputId": "f156a7a3-3eb3-46a3-8ea1-8b7e284e1cfa"
      },
      "source": [
        "!ls -R '/content/FullIJCNN2013/Train'"
      ],
      "id": "vHRpyQMjcx0g",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/FullIJCNN2013/Train': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "KBtkcBT4bJow",
        "outputId": "fb515976-9f5c-4c9b-dc85-7d94d8c3c0b2"
      },
      "source": [
        "# Number of Classes\n",
        "NUM_CATEGORIES = len(os.listdir(train_path))\n",
        "NUM_CATEGORIES"
      ],
      "id": "KBtkcBT4bJow",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-45415b9df812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Number of Classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNUM_CATEGORIES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mNUM_CATEGORIES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/FullIJCNN2013/Train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkihGVmAa4Jr"
      },
      "source": [
        "# Visualizing all the different Signs\n",
        "import pathlib\n",
        "import cv2\n",
        "import glob\n",
        "img_dir = pathlib.Path(train_path)\n",
        "plt.figure(figsize=(14,14))\n",
        "index = 0\n",
        "for i in range(NUM_CATEGORIES-1):\n",
        "    plt.subplot(7, 7, i+1)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    sign = list(img_dir.rglob(f'{i}/*'))[0]\n",
        "    img = load_img(sign, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "id": "QkihGVmAa4Jr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SngGy8Dnj8xx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "SngGy8Dnj8xx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUY3yNrdaABY"
      },
      "source": [
        "### Data Exploration and Preprocessing ( 2 points)"
      ],
      "id": "NUY3yNrdaABY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ca63666"
      },
      "source": [
        "#### Plot the sample image of each class\n",
        "\n",
        "Hint: plt.subplot"
      ],
      "id": "9ca63666"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c414e14e"
      },
      "source": [
        "# Label Overview\n",
        "classes = { 0:'Speed limit (20km/h)',\n",
        "            1:'Speed limit (30km/h)', \n",
        "            2:'Speed limit (50km/h)', \n",
        "            3:'Speed limit (60km/h)', \n",
        "            4:'Speed limit (70km/h)', \n",
        "            5:'Speed limit (80km/h)', \n",
        "            6:'End of speed limit (80km/h)', \n",
        "            7:'Speed limit (100km/h)', \n",
        "            8:'Speed limit (120km/h)', \n",
        "            9:'No passing', \n",
        "            10:'No passing veh over 3.5 tons', \n",
        "            11:'Right-of-way at intersection', \n",
        "            12:'Priority road', \n",
        "            13:'Yield', \n",
        "            14:'Stop', \n",
        "            15:'No vehicles', \n",
        "            16:'Veh > 3.5 tons prohibited', \n",
        "            17:'No entry', \n",
        "            18:'General caution', \n",
        "            19:'Dangerous curve left', \n",
        "            20:'Dangerous curve right', \n",
        "            21:'Double curve', \n",
        "            22:'Bumpy road', \n",
        "            23:'Slippery road', \n",
        "            24:'Road narrows on the right', \n",
        "            25:'Road work', \n",
        "            26:'Traffic signals', \n",
        "            27:'Pedestrians', \n",
        "            28:'Children crossing', \n",
        "            29:'Bicycles crossing', \n",
        "            30:'Beware of ice/snow',\n",
        "            31:'Wild animals crossing', \n",
        "            32:'End speed + passing limits', \n",
        "            33:'Turn right ahead', \n",
        "            34:'Turn left ahead', \n",
        "            35:'Ahead only', \n",
        "            36:'Go straight or right', \n",
        "            37:'Go straight or left', \n",
        "            38:'Keep right', \n",
        "            39:'Keep left', \n",
        "            40:'Roundabout mandatory', \n",
        "            41:'End of no passing', \n",
        "            42:'End no passing veh > 3.5 tons' }"
      ],
      "id": "c414e14e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcXy4IsjgqJe"
      },
      "source": [
        "folders = os.listdir('/content/FullIJCNN2013/Train')"
      ],
      "id": "QcXy4IsjgqJe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO9JOl6Tgs4K"
      },
      "source": [
        "folders.remove('.ipynb_checkpoints')\n"
      ],
      "id": "ZO9JOl6Tgs4K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFfol1FNhI7X"
      },
      "source": [
        "folders"
      ],
      "id": "fFfol1FNhI7X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0yUAbOlUw2m"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "train_number = []\n",
        "class_num = []\n",
        "removeFile ='.ipynb_checkpoints'\n",
        "for folder in folders:\n",
        "    train_files = os.listdir(train_path + '/' + folder)\n",
        "\n",
        "    train_number.append(len(train_files))\n",
        "    \n",
        "    print(\"---\", train_path + '/' + folder)\n",
        "    print(\"---\", train_files)\n",
        "    try:\n",
        "      if (folder != removeFile ): \n",
        "       class_num.append(classes[int(folder)])\n",
        "    except StopIteration:\n",
        "        break\n",
        "     \n",
        "plt.figure(figsize=(21,10))  \n",
        "class_num.count\n",
        "plt.bar(class_num, train_number)\n",
        "plt.xticks(class_num, rotation='vertical')\n",
        "plt.show()"
      ],
      "id": "I0yUAbOlUw2m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2rqCM-sIbY"
      },
      "source": [
        "#### Plot the distribution of Classes"
      ],
      "id": "8a2rqCM-sIbY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwWKGQMFsIDP"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "nwWKGQMFsIDP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy7cN3PvfAum"
      },
      "source": [
        "def load_data(data_dir):\n",
        "    images = list()\n",
        "    labels = list()\n",
        "    for category in range(NUM_CATEGORIES-1):\n",
        "        categories = os.path.join(data_dir, str(category))\n",
        "        for img in os.listdir(categories):\n",
        "          sign = list(img_dir.glob(f'{i}/*'))[0]\n",
        "          img = load_img(sign, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
        "          image = img_to_array(img)\n",
        "          images.append(image)\n",
        "          labels.append(category)  \n",
        "    return images, labels"
      ],
      "id": "zy7cN3PvfAum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZswA04yEfDso"
      },
      "source": [
        "images, labels = load_data(train_path)"
      ],
      "id": "ZswA04yEfDso",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ZRm1AOfGnW"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "labels = to_categorical(labels)"
      ],
      "id": "j9ZRm1AOfGnW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT9KOHf0fJ0O"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(np.array(images), labels, test_size=0.3)"
      ],
      "id": "oT9KOHf0fJ0O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37b23a0b"
      },
      "source": [
        "#### Normalize the features\n",
        "\n",
        "For most image data, the pixel values are integers with values between 0 and 255.\n",
        "\n",
        "Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values.\n",
        "\n",
        "Hint: sklearn.preprocessing.normalize"
      ],
      "id": "37b23a0b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82239736"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "X_train/=255\n",
        "X_test/=255\n",
        "print('x_train shape:',X_train.shape)\n",
        "print('Number of images in x_train',X_train.shape[0])\n",
        "print('Number of images in x_test',X_test.shape[0])"
      ],
      "id": "82239736",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewXkjGbd7Obj"
      },
      "source": [
        "input_shape=( 30, 30, 3)"
      ],
      "id": "ewXkjGbd7Obj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2iUtF197JUi"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, MaxPooling2D\n",
        "model = Sequential()\n",
        "\n",
        "# First Convolutional Layer\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "# Second Convolutional Layer\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "# Third Convolutional Layer\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(NUM_CATEGORIES-1, activation='softmax'))\n",
        "\n",
        "# Compiling the model\n",
        "\n",
        "\n",
        "lr = 0.001\n",
        "epochs = 30\n",
        "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "id": "E2iUtF197JUi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npX7OSagAoUn"
      },
      "source": [
        "def build_model(n_hidden=1, n_neurons=43, learning_rate=3e-3, input_shape=[8]):\n",
        "    model = Sequential()\n",
        "    options = {\"input_shape\": input_shape}\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(Dense(n_neurons, activation=\"relu\", **options))\n",
        "        options = {}\n",
        "    model.add(Dense(1, **options))\n",
        "    optimizer = SGD(learning_rate)\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    return model"
      ],
      "id": "npX7OSagAoUn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ea9c3a"
      },
      "source": [
        "### Train the MLP classifier on features (1 point)\n",
        "\n",
        "* Split the data into train and test\n",
        "\n",
        "* Train the MLP classifier with different parameters\n",
        "\n",
        "* Get the accuracy score and performance metrics"
      ],
      "id": "28ea9c3a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f952950"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "history = model.fit(X_train, y_train,validation_split=0.3,epochs=20)"
      ],
      "id": "7f952950",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N6lOI5z76kM"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('test set accuracy: ', accuracy * 100)"
      ],
      "id": "5N6lOI5z76kM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am0WZu3x8PLw"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "id": "am0WZu3x8PLw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdS550S68TEj"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "for i in range(36):\n",
        "  pyplot.subplot(6,6,i+1)\n",
        "  pyplot.imshow(X_test[i])\n",
        "  "
      ],
      "id": "UdS550S68TEj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O2htCuc8XuD"
      },
      "source": [
        "image_index=0"
      ],
      "id": "4O2htCuc8XuD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO3gRhKP8akf"
      },
      "source": [
        "plt.imshow(X_test[image_index])\n",
        "n = np.array(X_test[image_index])\n",
        "print(n.size)\n",
        "p = n.reshape(1, 30, 30, 3)\n",
        "pred = classes[model.predict(p).argmax()]\n",
        "\n",
        "print(\"The predicted image is {}\".format(pred))"
      ],
      "id": "TO3gRhKP8akf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfe1e294"
      },
      "source": [
        "### Tune the hyper-parameters (2 points)\n",
        "\n",
        "* Use the GridSearchCV or RandomizedSearchCV and select best parameters\n",
        "\n",
        "  Hint: [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
        "\n",
        "  (or)\n",
        "* Manually change and find the best parameters\n",
        "\n",
        "To know about all the parameters, click [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
      ],
      "id": "dfe1e294"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTOtaQKkHYyo"
      },
      "source": [
        " X_train.shape"
      ],
      "id": "oTOtaQKkHYyo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye2e7Gx7IWLU"
      },
      "source": [
        "X_test.shape"
      ],
      "id": "Ye2e7Gx7IWLU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTYCSkknUNNC"
      },
      "source": [
        "nsamples, nx, ny, o = X_train.shape\n",
        "X_train = X_train.reshape((nsamples,nx*ny*o))\n",
        "ntestsamples, ntestx, ntesty, testo = X_test.shape\n",
        "X_test = X_test.reshape((ntestsamples,ntestx*ntesty*testo))"
      ],
      "id": "sTYCSkknUNNC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_AZN8A2JEYX"
      },
      "source": [
        "ntestsamples, ntestx, ntesty, testo = X_test.shape\n",
        "X_test = X_test.reshape((ntestsamples,ntestx*ntesty*testo))"
      ],
      "id": "j_AZN8A2JEYX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqGYdP2mAhlz"
      },
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(model)"
      ],
      "id": "iqGYdP2mAhlz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIPHXpkqC70k"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "id": "BIPHXpkqC70k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f29ce38e"
      },
      "source": [
        "# pylint: disable=unused-argument\n",
        "from scipy.stats import reciprocal\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(1, 100),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
        "}"
      ],
      "id": "f29ce38e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vbcQRqd-q2v"
      },
      "source": [
        "# defining early stop \n",
        "from keras.callbacks import EarlyStopping \n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
      ],
      "id": "2vbcQRqd-q2v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8eO3cYD_rb_"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                  validation_data=(X_test,y_test),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)]) "
      ],
      "id": "b8eO3cYD_rb_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "witL3SQL_vg4"
      },
      "source": [
        "# finding the best parameters\n",
        "rnd_search_cv.best_params_"
      ],
      "id": "witL3SQL_vg4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXSBeKMM_x-n"
      },
      "source": [
        "# best score\n",
        "rnd_search_cv.best_score_"
      ],
      "id": "nXSBeKMM_x-n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGCcy9hx_-Qi"
      },
      "source": [
        "# applying best parameters to the model for predictions\n",
        "model = rnd_search_cv.best_estimator_.model"
      ],
      "id": "TGCcy9hx_-Qi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "911d0a39"
      },
      "source": [
        "#### Try the different algorithms and compare the results with MLP classifier"
      ],
      "id": "911d0a39"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08b0c234"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "08b0c234",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af9cd34e"
      },
      "source": [
        "### Implement simple Neural Networks using keras (3 points)\n",
        "\n",
        "* Define the keras model and initialize the layers\n",
        "  - Ensure the input layer has the right number of input features. This can be specified when creating the first layer with the input_dim argument.\n",
        "* Compile the model\n",
        "  - Specify the loss function (to evaluate a set of weights), the optimizer (is used to search through different weights for the network) and any optional metrics to collect and report during training.\n",
        "* Fit and Evaluate the model\n",
        "  - Fit the data by specifying epochs and evaluate the model"
      ],
      "id": "af9cd34e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcf8d025"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "id": "fcf8d025",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ecbe0db"
      },
      "source": [
        "# Step 1 - Build the architecture\n",
        "# YOUR CODE HERE"
      ],
      "id": "1ecbe0db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4c7bc66"
      },
      "source": [
        "# Step 2 - Compile the model\n",
        "# YOUR CODE HERE"
      ],
      "id": "d4c7bc66",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Pltot4FsiG"
      },
      "source": [
        "# Step 3 - Fit and Evaluate the model\n",
        "# YOUR CODE HERE"
      ],
      "id": "27Pltot4FsiG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSUDO2lLmQJO"
      },
      "source": [
        "#### Try the same parameters used for MLP Classifier and build the keras model"
      ],
      "id": "cSUDO2lLmQJO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zNp5w4bvFz9"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "1zNp5w4bvFz9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAHzeVx_tImO"
      },
      "source": [
        "#### Experiment using Dropout, Regularization and Batch Normalization"
      ],
      "id": "IAHzeVx_tImO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w34gbejXvLUs"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "w34gbejXvLUs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhWaGRRfs7tv"
      },
      "source": [
        "### Report Analysis\n",
        "\n",
        "* According to the confusion matrix, for which sign were the maximum misclassifications observed? Comment on the misclassification, owing to similar appearing traffic signs, if any. \n",
        "* Comment on the performance of the MLP Classifier\n",
        "* Discuss the optimal number of layers, activation functions, optimizers etc. that yielded the best accuracy\n",
        "* Report on training time vs convergence"
      ],
      "id": "MhWaGRRfs7tv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4978243"
      },
      "source": [
        "Reference: J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German Traffic Sign Recognition Benchmark: A multi-class classification competition. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 1453–1460. 2011."
      ],
      "id": "d4978243"
    }
  ]
}