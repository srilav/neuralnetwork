{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "M4_AST_07_Autoencoders_C.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilav/neuralnetwork/blob/main/M4_AST_07_Autoencoders_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Q8Cm2wpDzs"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Assignment 7: Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EctoCIzVpDzv"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-efqOk1pDzw"
      },
      "source": [
        "At the end of the experiment, you will be able to\n",
        "\n",
        "* know what are autoencoders\n",
        "* know different kinds of autoencoders: stacked, and denoising\n",
        "* perform dimensionality reduction using autoencoder\n",
        "* perform anomaly detection using autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBEj4s9upDzy"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEchYDLFpDzz"
      },
      "source": [
        "Autoencoders are artificial neural networks capable of learning dense representations of the input data, called **latent representations** or **codings**, without any supervision (unlabeled training set). These codings typically have a much lower dimensionality than the input data, making autoencoders useful for dimensionality reduction.\n",
        "\n",
        "Autoencoders also act as feature detectors, and they can be used for unsupervised pretraining of deep neural networks. Some autoencoders are generative models: they are capable of randomly generating new data that looks very similar to the training data.\n",
        "\n",
        "**Working of autoencoders:**\n",
        "\n",
        "Autoencoders learn to copy their inputs to their outputs, by constraining the network in various ways, such as, by limiting the size of the latent representations, or by adding noise to the inputs and train the network to recover the original inputs. These constraints force the autoencoder to learn efficient ways of representing the data and prevent it from trivially copying the inputs directly to the outputs. In short, the codings are byproducts of the autoencoder learning the identity function under some constraints.\n",
        "\n",
        "An autoencoder is composed of two parts: \n",
        "\n",
        "* an **encoder** (or recognition network) that converts the inputs to a latent representation, followed by \n",
        "\n",
        "* a **decoder** (or generative network) that converts the internal representation to the outputs.\n",
        "<br><br>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/1400/1*V_YtxTFUqDrmmu2JqMZ-rA.png\" width=600px/>\n",
        "</center>\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cda6gjqppDz0"
      },
      "source": [
        "An autoencoder has the same architecture as a Multi-Layer Perceptron, except that the number of neurons in the input and output layers must be equal. The outputs are often called the **reconstructions**, and the cost function contains a **reconstruction loss** that penalizes the model when the reconstructions are different from the inputs.\n",
        "\n",
        "When the internal representation has a lower dimensionality than the input data as shown in the figure below, the autoencoder is said to be **Undercomplete Autoencoder**.\n",
        "\n",
        "<br><br>\n",
        "<center>\n",
        "<img src=\"https://www.compthree.com/images/blog/ae/ae.png\" width=500px/>\n",
        "</center>\n",
        "\n",
        "$\\hspace{10.8cm} \\text{A Simple Autoencoder}$\n",
        "<br><br>\n",
        "\n",
        "Let’s see how to implement dimensionality reduction using an undercomplete autoencoder having multiple hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"M4_AST_07_Autoencoders_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")  \n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/CDS/Datasets/ecg.csv\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://cds.iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcE6AhfWpDz2"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-hqBgzlpDz3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape, GaussianNoise, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krQVQ2TgpDz4"
      },
      "source": [
        "### Stacked Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGDrATW2pDz6"
      },
      "source": [
        "When autoencoders have multiple hidden layers, they are called **stacked autoencoders** (or **deep autoencoders**). Adding more layers helps the autoencoder learn more complex codings. The architecture of a stacked autoencoder is typically **symmetrical** with regard to the central hidden layer (the coding layer).\n",
        "\n",
        "For example, an autoencoder for MNIST may have 784 inputs, followed by a hidden layer with 300 neurons, then a central hidden layer of 150 neurons, then another hidden layer with 300 neurons, and an output layer with 784 neurons. This stacked autoencoder is represented in the figure below.\n",
        "\n",
        "<br><br>\n",
        "<center>\n",
        "<img src=\"https://www.programmersought.com/images/827/3a4063a8e0c49eae7a3f6c4af55df64b.png\" width=550px/>\n",
        "</center>\n",
        "\n",
        "$\\hspace{9.55cm} \\text{Stacked Autoencoder}$\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OtoA1uOpDz7"
      },
      "source": [
        "#### Implementing a Stacked Autoencoder Using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtaEO3bfpDz8"
      },
      "source": [
        "Let's use Fashion MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZYWWDwcpDz8"
      },
      "source": [
        "# Load fasion mnist dataset\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Scale dataset\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "\n",
        "# Training and validation set\n",
        "X_train = X_train_full[:-5000]\n",
        "X_valid = X_train_full[-5000:]\n",
        "y_train = y_train_full[:-5000]\n",
        "y_valid = y_train_full[-5000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV8jbtehpDz9"
      },
      "source": [
        "Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UgQTDAJpDz-"
      },
      "source": [
        "# Create stacked encoder\n",
        "stacked_encoder = Sequential([\n",
        "                              Flatten(input_shape=[28, 28]),\n",
        "                              Dense(100, activation=\"selu\"),\n",
        "                              Dense(30, activation=\"selu\"),\n",
        "                              ])\n",
        "\n",
        "# Create stacked decoder\n",
        "stacked_decoder = Sequential([\n",
        "                              Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "                              Dense(28 * 28, activation=\"sigmoid\"),\n",
        "                              Reshape([28, 28])\n",
        "                              ])\n",
        "\n",
        "# Create stacked autoencoder\n",
        "stacked_ae = Sequential([stacked_encoder, stacked_decoder])\n",
        "\n",
        "# Compile model\n",
        "def rounded_accuracy(y_true, y_pred):\n",
        "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))\n",
        "\n",
        "stacked_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate = 1.5), metrics = [rounded_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvdMg1sWpDz_"
      },
      "source": [
        "# Train stacked autoencoder on training set\n",
        "history = stacked_ae.fit(X_train, X_train, epochs=20, validation_data=(X_valid, X_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WF39I01pD0B"
      },
      "source": [
        "For creating stacked autoencoder:\n",
        "\n",
        "* We split the autoencoder model into two submodels: the encoder and the decoder.\n",
        "\n",
        "* The encoder takes 28 × 28–pixel grayscale images, flattens them as a vector of size 784, then processes these vectors through two Dense layers of diminishing sizes (100 units then 30 units), both using the SELU activation function. For each input image, the encoder outputs a vector of size 30.\n",
        "\n",
        "* The decoder takes codings of size 30 (output by the encoder) and processes them through two Dense layers of increasing sizes (100 units then 784 units), and it reshapes the final vectors into 28 × 28 arrays so the decoder’s outputs have the same shape as the encoder’s inputs.\n",
        "\n",
        "* When compiling the stacked autoencoder, we use the binary cross-entropy loss instead of the mean squared error. We are treating the reconstruction task as a multilabel binary classification problem: each pixel intensity represents the probability that the pixel should be black. Framing it this way (rather than as a regression problem) tends to make the model converge faster.\n",
        "\n",
        "* Finally, we train the model using X_train as both the inputs and the targets (and similarly, we use X_valid as both the validation inputs and targets).\n",
        "\n",
        "To compare the inputs and the outputs, let’s plot a few images from the validation set, as well as their reconstructions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m_QxSA5pD0C"
      },
      "source": [
        "def show_reconstructions(model, images=X_valid, n_images=5):\n",
        "    ''' Compare inputs and outputs of model using n_images from X_valid dataset '''\n",
        "\n",
        "    reconstructions = model.predict(images[:n_images])\n",
        "\n",
        "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
        "    for img_idx in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + img_idx)\n",
        "        plt.imshow(images[img_idx], cmap='binary')\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(2, n_images, 1 + n_images + img_idx)\n",
        "        plt.imshow(reconstructions[img_idx], cmap='binary')\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "# Visualize reconstructions\n",
        "show_reconstructions(model = stacked_ae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pT6J2p7pD0C"
      },
      "source": [
        "From the above results, we can see that the reconstructions are recognizable, but a bit too lossy. We may need to train the model for longer, or make the encoder and decoder deeper, or make the codings larger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LecSYuvpD0C"
      },
      "source": [
        "<font color='blue'>**Discussion 1:** We train the stacked autoencoder using X_train as both the inputs and the targets but for training the encoder we use X_train as the input only. Why? </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jPoYNtQpD0D"
      },
      "source": [
        "#### Visualizing Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-3YbKkzpD0D"
      },
      "source": [
        "We can use trained stacked autoencoder to reduce the dataset’s dimensionality. One big advantage of autoencoders is that they can handle large datasets, with many instances and many features. So we can use an autoencoder to reduce the dimensionality down to a reasonable level, then use another dimensionality reduction algorithm for visualization. \n",
        "\n",
        "Let’s use this strategy to visualize Fashion MNIST. First, we use the encoder from our stacked autoencoder to reduce the dimensionality down to 30, then we use Scikit-Learn’s t-SNE algorithm to reduce the dimensionality down to 2 for visualization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf73cYC8pD0E"
      },
      "source": [
        "# Predict codings\n",
        "X_valid_compressed = stacked_encoder.predict(X_valid)\n",
        "\n",
        "# Implement t-SNE\n",
        "tsne = TSNE()\n",
        "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
        "\n",
        "# Normalize \n",
        "X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbRNZloGpD0E"
      },
      "source": [
        "# Visualize Fashion MNIST\n",
        "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0gWLDMLpD0F"
      },
      "source": [
        "From the above plot, we can see that the t-SNE algorithm identified several clusters which match the classes reasonably well (each class is represented with a different color)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHlOO402pD0F"
      },
      "source": [
        "Till now, in order to force the autoencoder to learn interesting features, we have limited the size of the coding layer, making it undercomplete. Other kinds of constraints allow the coding layer to be just as large as the inputs, or even larger, resulting in an **overcomplete autoencoder**, such as:\n",
        "\n",
        "* Denoising Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGEiZ1cqpD0F"
      },
      "source": [
        "### Denoising Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d10tv0wpD0G"
      },
      "source": [
        "Another way to force the autoencoder to learn useful features is to add noise to its inputs, and training it to recover the original, noise-free inputs. In a 2008 paper, Pascal Vincent et al. showed that autoencoders could also be used for feature extraction. In a 2010 paper, Vincent et al. introduced stacked denoising autoencoders. \n",
        "\n",
        "The noise can be \n",
        "\n",
        "* pure **Gaussian noise** added to the inputs, or \n",
        "\n",
        "* randomly switched-off inputs, just like in **dropout** \n",
        "\n",
        "The below figure shows both options.\n",
        "<br><br>\n",
        "<center>\n",
        "<img src=\"https://www.programmersought.com/images/233/76dabd18e2cc55b6f6e9969220005ce9.png\" width=500px/>\n",
        "</center>\n",
        "\n",
        "$\\hspace{5.5cm} \\text{Denoising autoencoders, with Gaussian noise (left) and dropout (right)}$\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiHSIpQapD0G"
      },
      "source": [
        "Let's implement denoising autoencoder to the Fashion MNIST dataset.\n",
        "\n",
        "Using Gaussian noise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb9PltRTpD0G"
      },
      "source": [
        "# Create denoising encoder\n",
        "denoising_encoder = Sequential([\n",
        "                                Flatten(input_shape=[28, 28]),\n",
        "                                GaussianNoise(0.2),\n",
        "                                Dense(100, activation=\"selu\"),\n",
        "                                Dense(30, activation=\"selu\")\n",
        "                                ])\n",
        "# Create denoising decoder\n",
        "denoising_decoder = Sequential([\n",
        "                                Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "                                Dense(28 * 28, activation=\"sigmoid\"),\n",
        "                                Reshape([28, 28])\n",
        "                                ])\n",
        "# Create denoising autoencoder\n",
        "denoising_ae = Sequential([denoising_encoder, denoising_decoder])\n",
        "# Compile model\n",
        "denoising_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0), metrics=[rounded_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRCNMWPepD0H"
      },
      "source": [
        "# Train denoising autoencoder on training set\n",
        "history = denoising_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5N_yQxtpD0H"
      },
      "source": [
        "# Visualize reconstructions\n",
        "noise = GaussianNoise(0.2)\n",
        "show_reconstructions(denoising_ae, noise(X_valid, training=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byy2hyVcpD0I"
      },
      "source": [
        "<font color='blue'>**Discussion 2:** In the above code cell, why do we need to pass X_valid to a separate `GaussianNoise` layer, although a `GaussianNoise` layer is already there in denoising_encoder submodel? </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHGh66hlpD0I"
      },
      "source": [
        "Using dropout:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDqUuCCNpD0I"
      },
      "source": [
        "# Create encoder\n",
        "dropout_encoder = Sequential([\n",
        "                              Flatten(input_shape=[28, 28]),\n",
        "                              Dropout(0.5),\n",
        "                              Dense(100, activation=\"selu\"),\n",
        "                              Dense(30, activation=\"selu\")\n",
        "                              ])\n",
        "# Create decoder\n",
        "dropout_decoder = Sequential([\n",
        "                              Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "                              Dense(28 * 28, activation=\"sigmoid\"),\n",
        "                              Reshape([28, 28])\n",
        "                              ])\n",
        "# Create autoencoder\n",
        "dropout_ae = Sequential([dropout_encoder, dropout_decoder])\n",
        "# Compile model\n",
        "dropout_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.0), metrics=[rounded_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW_fdkpepD0I"
      },
      "source": [
        "# Training autoencoder on training set\n",
        "history = dropout_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IovXTBK9pD0J"
      },
      "source": [
        "# Visualize reconstructions\n",
        "dropout = Dropout(0.5)\n",
        "show_reconstructions(dropout_ae, dropout(X_valid, training=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFczuUV7pD0J"
      },
      "source": [
        "### Anomaly Detection using Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBSWLrKhpD0K"
      },
      "source": [
        "One practical application of autoencoders is anomaly detection. \n",
        "\n",
        "Let's see how to use autoencoder for detecting anomalies in ECG (electrocardiogram) readings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qq9NuMDpD0K"
      },
      "source": [
        "# Read ecg dataset\n",
        "df = pd.read_csv('ecg.csv', header=None)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf7ITEIgpD0K"
      },
      "source": [
        "As we can see that the dataset has 140 columns which represent the ECG readings and a labels column that has been encoded to 0 or 1 showing whether the ECG is abnormal or normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AivRcrDYpD0L"
      },
      "source": [
        "# Separate the data and labels\n",
        "data = df.iloc[:,:-1].values\n",
        "labels = df.iloc[:,-1].values\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocCPBq1epD0L"
      },
      "source": [
        "# Split into training and test data\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = 0.2, random_state = 21)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRn6LuckpD0L"
      },
      "source": [
        "Let's normalize the data to the range 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G90ZFA0pD0M"
      },
      "source": [
        "# Calculate the maximum and minimum value from the training set \n",
        "min = tf.reduce_min(train_data)\n",
        "max = tf.reduce_max(train_data)\n",
        "\n",
        "# Normalize data using the formula (data - min)/(max - min)\n",
        "train_data = (train_data - min)/(max - min)\n",
        "test_data = (test_data - min)/(max - min)\n",
        "\n",
        "# Converted the data into float\n",
        "train_data = tf.cast(train_data, dtype=tf.float32)\n",
        "test_data = tf.cast(test_data, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHtl1SUCpD0M"
      },
      "source": [
        "The labels are either 0 or 1, so we will convert them into boolean (true or false) and separate the data for normal ECG from that of abnormal ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b10n_UarpD0M"
      },
      "source": [
        "# Convert labels into boolean \n",
        "train_labels = train_labels.astype(bool)\n",
        "test_labels = test_labels.astype(bool)\n",
        "\n",
        "# Normal ECG data\n",
        "n_train_data = train_data[train_labels]\n",
        "n_test_data = test_data[test_labels]\n",
        "\n",
        "# Abnormal ECG data\n",
        "an_train_data = train_data[~train_labels]\n",
        "an_test_data = test_data[~test_labels]\n",
        "\n",
        "print(n_train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvF3FFV_pD0N"
      },
      "source": [
        "# Visualize a normal ECG\n",
        "plt.plot(np.arange(140), n_train_data[0])\n",
        "plt.grid()\n",
        "plt.title('Normal ECG')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtk86k-tpD0N"
      },
      "source": [
        "# Visualize an abnormal ECG\n",
        "plt.plot(np.arange(140), an_train_data[0])\n",
        "plt.grid()\n",
        "plt.title('Abnormal ECG')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yYWQCfApD0O"
      },
      "source": [
        "**How will the model detect an anomaly?**\n",
        "\n",
        "We will create an encoder and a decoder using an ANN architecture. We are going to provide the ECG data as input and the model will try to reconstruct it. The error between the original data and the reconstructed output will be called the **reconstruction error**. Based on this reconstruction error we are going to classify an ECG as anomalous or not. \n",
        "\n",
        "To do this, we are going to train the model only on the normal ECG data but it will be tested on the full test set so that when an abnormal ECG is provided in the input the autoencoder will try to reconstruct it but since it has been only trained on normal ECG data the output will have a larger reconstruction error. We will also define a minimum threshold for the error i.e. if the reconstruction error is above the threshold then it will be categorized as anomalous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4mIisIopD0O"
      },
      "source": [
        "# Create encoder submodel\n",
        "encoder = Sequential([Dense(32, activation='relu', input_shape=[140]),\n",
        "                      Dense(16, activation='relu'),\n",
        "                      Dense(8, activation='relu')\n",
        "                      ])\n",
        "\n",
        "# Create decoder submodel\n",
        "decoder = Sequential([Dense(16, activation='relu', input_shape=[8]),\n",
        "                      Dense(32, activation='relu'),\n",
        "                      Dense(140, activation='sigmoid')\n",
        "                      ])\n",
        "\n",
        "# Create autoencoder\n",
        "autoencoder = Sequential([encoder, decoder])\n",
        "\n",
        "# Compile model\n",
        "autoencoder.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "# Fit model\n",
        "autoencoder.fit(n_train_data, n_train_data, epochs = 20, batch_size=512, validation_data=(n_test_data, n_test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hI1eEwApD0P"
      },
      "source": [
        "Now let's define a function in order to plot the original ECG and reconstructed ones and also show the error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0LwnIQhpD0P"
      },
      "source": [
        "def plot(data, n):\n",
        "    ''' Plot the original ECG and reconstructed ECG along with the error '''\n",
        "    enc_img = encoder(data)\n",
        "    dec_img = decoder(enc_img)\n",
        "    plt.plot(data[n], 'b')\n",
        "    plt.plot(dec_img[n], 'r')\n",
        "    plt.fill_between(np.arange(140), data[n], dec_img[n], color = 'lightcoral')\n",
        "    plt.legend(labels=['Input', 'Reconstruction', 'Error'])\n",
        "    plt.show()\n",
        "\n",
        "plot(n_test_data, 0)\n",
        "plot(an_test_data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FduCQ0lLpD0P"
      },
      "source": [
        "As we mentioned earlier an ECG is anomalous if it is greater than a threshold. We can set the threshold in any way we want. Here we set it to one standard deviation from the mean of normal training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MTbUrCIpD0Q"
      },
      "source": [
        "# Compute threshold\n",
        "reconstructed = autoencoder(n_train_data)\n",
        "train_loss = losses.mae(reconstructed, n_train_data)\n",
        "t = np.mean(train_loss) + np.std(train_loss)\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY3Gc0QHpD0Q"
      },
      "source": [
        "def prediction(model, data, threshold):\n",
        "    ''' Returns True if the reconstruction error is below the threshold '''\n",
        "    rec = model(data)\n",
        "    loss = losses.mae(rec, data)\n",
        "    return tf.math.less(loss, threshold)\n",
        "\n",
        "pred = prediction(autoencoder, n_test_data, t)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlSwd80kpD0Q"
      },
      "source": [
        "From the above results, we can see that for the normal ECG test dataset, only few of the instances are marked as False i.e, above threshold. \n",
        "\n",
        "Let's see some more results visually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuvbAQSUpD0R"
      },
      "source": [
        "# Visualize some normal ECG test instances\n",
        "plot(n_test_data, 0)\n",
        "plot(n_test_data, 1)\n",
        "plot(n_test_data, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYd49WvopD0R"
      },
      "source": [
        "From the above results, we can see that the model can be improved by hyperparameter tuning. Also, the criteria for determining the threshold can be changed for getting better and more accurate results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPWFqO8cpD0R"
      },
      "source": [
        "### Theory Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykDp8M44pD0S"
      },
      "source": [
        "1. What are the main tasks that autoencoders are used for?\n",
        "\n",
        " Here are some of the main tasks that autoencoders are used for:\n",
        "  * Feature extraction\n",
        "  * Unsupervised pretraining\n",
        "  * Dimensionality reduction\n",
        "  * Generative models\n",
        "  * Anomaly detection (an autoencoder is generally bad at reconstructing outliers)\n",
        "\n",
        "2. Suppose you want to train a classifier, and you have plenty of unlabeled training data but only a few thousand labeled instances. How can autoencoders help? How would you proceed?\n",
        "\n",
        " If you want to train a classifier and you have plenty of unlabeled training data but only a few thousand labeled instances, then you could first train a deep autoencoder on the full dataset (labeled + unlabeled), then reuse its lower half for the classifier (i.e., reuse the layers up to the codings layer, included) and train the classifier using the labeled data. If you have little labeled data, you probably want to freeze the reused layers when training the classifier.\n",
        "\n",
        "3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good\n",
        "autoencoder? How can you evaluate the performance of an autoencoder?\n",
        "\n",
        " The fact that an autoencoder perfectly reconstructs its inputs does not necessarily mean that it is a good autoencoder; perhaps it is simply an overcomplete autoencoder that learned to copy its inputs to the codings layer and then to the outputs. However, if it produces very bad reconstructions, then it is almost guaranteed to be a bad autoencoder. \n",
        "\n",
        " To evaluate the performance of an autoencoder, one option is to measure the\n",
        "reconstruction loss (e.g., compute the MSE, or the mean square of the outputs\n",
        "minus the inputs). Again, a high reconstruction loss is a good sign that the\n",
        "autoencoder is bad, but a low reconstruction loss is not a guarantee that it is\n",
        "good. You should also evaluate the autoencoder according to what it will be used\n",
        "for. For example, if you are using it for unsupervised pretraining of a classifier, then you should also evaluate the classifier’s performance.\n",
        "\n",
        "4. What are undercomplete and overcomplete autoencoders? What is the main risk\n",
        "of an excessively undercomplete autoencoder? What about the main risk of an\n",
        "overcomplete autoencoder?\n",
        "\n",
        " An undercomplete autoencoder is one whose codings layer is smaller than the\n",
        "input and output layers. If it is larger, then it is an overcomplete autoencoder. The main risk of an excessively undercomplete autoencoder is that it may fail to reconstruct the inputs. The main risk of an overcomplete autoencoder is that it may just copy the inputs to the outputs, without learning any useful features.\n",
        "\n",
        "5. How do you tie weights in a stacked autoencoder? What is the point of doing so?\n",
        "\n",
        " To tie the weights of an encoder layer and its corresponding decoder layer, you\n",
        "simply make the decoder weights equal to the transpose of the encoder weights.\n",
        "This reduces the number of parameters in the model by half, often making training converge faster with less training data and reducing the risk of overfitting the training set.\n",
        "\n",
        "6. What is a generative model? Can you name a type of generative autoencoder?\n",
        "\n",
        " A generative model is a model capable of randomly generating outputs that\n",
        "resemble the training instances. For example, once trained successfully on the\n",
        "MNIST dataset, a generative model can be used to randomly generate realistic\n",
        "images of digits. The output distribution is typically similar to the training data. For example, since MNIST contains many images of each digit, the generative model would output roughly the same number of images of each digit. Some generative models can be parametrized—for example, to generate only some\n",
        "kinds of outputs. An example of a generative autoencoder is the variational\n",
        "autoencoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "source": [
        "#@title Select the FALSE statement: { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\", \"Autoencoder is used for pattern recognition in unlabeled data\", \"For overcomplete autoencoder, the internal representation has a lower dimensionality than the input data\", \"For anomaly detection, autoencoder is trained only on the normal instances\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}