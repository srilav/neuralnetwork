{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilav/neuralnetwork/blob/main/2_Stacked_AutoEncoder_for_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa9uEvimN8tV"
      },
      "source": [
        "Stacked AutoEncoder:\n",
        "    1. just like other neural networks\n",
        "    2. autoencoders can have multiple hidden layers\n",
        "    3. in this case stacked autoencoders(or deep autoencoders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JefDifhN8tZ"
      },
      "source": [
        "Adding more layers:\n",
        "    1. helps the autoencoder learn more complex codings\n",
        "    \n",
        "One must be careful not to make the autoencoder too powerful:\n",
        "    1. imagine an encoder so powerful that is just learn to map each input to a single arbitrary number(and the decoder learns the reverse mapping)\n",
        "    2. Obviously such an autoencoder will reconstruct the training data perfectly\n",
        "    3. but it will not have learned any useful data reprenstation in the process\n",
        "    4. and it's unlikely to generalize well to new instances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf1jgjUaN8tZ"
      },
      "source": [
        "**Implementing a Stacked AutoEncoder Using Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUeVDgbEN8ta"
      },
      "source": [
        "you can implement a stacken autoencoder very much like a regular deep MLP\n",
        "    2. the following code builds a stacked AutoEncoder for Fashion MNIST(loaded and normalized)\n",
        "    3. Using the SELU activation function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TxzSdJ4N8ta"
      },
      "outputs": [],
      "source": [
        "#the following code builds a stacked AutoEncoder for Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HrHCzrCN8tc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyxAOJxFN8tc",
        "outputId": "6e5ae723-7932-43ca-9ecd-e93ca43697c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (55000, 28, 28)\n",
            "Number of images in x_train 55000\n",
            "Number of images in x_test 10000\n"
          ]
        }
      ],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "print('x_train shape:', X_train.shape)\n",
        "print('Number of images in x_train', X_train.shape[0])\n",
        "print('Number of images in x_test', X_test.shape[0])\n",
        "\n",
        "def rounded_accuracy(y_true, y_pred):\n",
        "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_index = 2000 # You may select anything up to 55000\n",
        "print(y_train[image_index])\n",
        "plt.imshow(X_train[image_index], cmap='Greys')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "gTcuHHVGRJ9Y",
        "outputId": "598fb665-22e9-439b-e34e-af070fdd9a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fddea203ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the encoding dimension to 32. \n",
        "# Use SeLu activation function for the hidden layers \n",
        "# and sigmoid function for the output layer with per-pixel binary cross entropy loss, \n",
        "# and the SGD optimizer with learning rate 1.5. \n",
        "# Show the training and validation loss for 20 epochs. "
      ],
      "metadata": {
        "id": "TCifjQDdPPbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0CIlUciN8td",
        "outputId": "cad10fc8-55ba-43c2-a27c-169c0bb250d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3381 - rounded_accuracy: 0.8870 - val_loss: 0.3165 - val_rounded_accuracy: 0.9004\n",
            "Epoch 2/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3056 - rounded_accuracy: 0.9152 - val_loss: 0.3021 - val_rounded_accuracy: 0.9201\n",
            "Epoch 3/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2986 - rounded_accuracy: 0.9215 - val_loss: 0.2985 - val_rounded_accuracy: 0.9199\n",
            "Epoch 4/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2948 - rounded_accuracy: 0.9249 - val_loss: 0.2937 - val_rounded_accuracy: 0.9285\n",
            "Epoch 5/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2923 - rounded_accuracy: 0.9272 - val_loss: 0.2919 - val_rounded_accuracy: 0.9284\n",
            "Epoch 6/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2904 - rounded_accuracy: 0.9289 - val_loss: 0.2915 - val_rounded_accuracy: 0.9305\n",
            "Epoch 7/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2890 - rounded_accuracy: 0.9301 - val_loss: 0.2907 - val_rounded_accuracy: 0.9280\n",
            "Epoch 8/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2877 - rounded_accuracy: 0.9314 - val_loss: 0.2943 - val_rounded_accuracy: 0.9299\n",
            "Epoch 9/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2869 - rounded_accuracy: 0.9321 - val_loss: 0.2907 - val_rounded_accuracy: 0.9256\n",
            "Epoch 10/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2859 - rounded_accuracy: 0.9330 - val_loss: 0.2878 - val_rounded_accuracy: 0.9309\n",
            "Epoch 11/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2851 - rounded_accuracy: 0.9336 - val_loss: 0.2866 - val_rounded_accuracy: 0.9348\n",
            "Epoch 12/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2845 - rounded_accuracy: 0.9341 - val_loss: 0.2856 - val_rounded_accuracy: 0.9355\n",
            "Epoch 13/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2840 - rounded_accuracy: 0.9346 - val_loss: 0.2847 - val_rounded_accuracy: 0.9354\n",
            "Epoch 14/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2835 - rounded_accuracy: 0.9349 - val_loss: 0.2844 - val_rounded_accuracy: 0.9365\n",
            "Epoch 15/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2830 - rounded_accuracy: 0.9355 - val_loss: 0.2841 - val_rounded_accuracy: 0.9353\n",
            "Epoch 16/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2826 - rounded_accuracy: 0.9358 - val_loss: 0.2845 - val_rounded_accuracy: 0.9356\n",
            "Epoch 17/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2823 - rounded_accuracy: 0.9360 - val_loss: 0.2835 - val_rounded_accuracy: 0.9363\n",
            "Epoch 18/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2819 - rounded_accuracy: 0.9363 - val_loss: 0.2831 - val_rounded_accuracy: 0.9363\n",
            "Epoch 19/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2816 - rounded_accuracy: 0.9365 - val_loss: 0.2827 - val_rounded_accuracy: 0.9375\n",
            "Epoch 20/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2813 - rounded_accuracy: 0.9368 - val_loss: 0.2840 - val_rounded_accuracy: 0.9368\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "stacked_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(30, activation=\"selu\"),\n",
        "])\n",
        "stacked_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
        "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
        "                   optimizer=keras.optimizers.SGD(lr=1.5), metrics=[rounded_accuracy])\n",
        "history = stacked_ae.fit(X_train, X_train, epochs=20,\n",
        "                         validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW_uxUIRN8tf"
      },
      "outputs": [],
      "source": [
        "28 * 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYtt68G0N8tf"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "2. Stacked AutoEncoder for MNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}